{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c30406eb-e12f-4edd-947d-4f905b5a4f05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T07:56:17.198186Z",
     "iopub.status.busy": "2025-02-02T07:56:17.197654Z",
     "iopub.status.idle": "2025-02-02T07:56:22.167517Z",
     "shell.execute_reply": "2025-02-02T07:56:22.166565Z",
     "shell.execute_reply.started": "2025-02-02T07:56:17.198160Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, set_seed, BitsAndBytesConfig\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import wandb\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4346da-9730-4d3c-b8cd-8e2b9f7a7d05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T07:56:22.169028Z",
     "iopub.status.busy": "2025-02-02T07:56:22.168362Z",
     "iopub.status.idle": "2025-02-02T07:56:22.182696Z",
     "shell.execute_reply": "2025-02-02T07:56:22.181720Z",
     "shell.execute_reply.started": "2025-02-02T07:56:22.168995Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_MODEL = \"meta-llama/Llama-3.2-1B\"\n",
    "PROJECT_NAME = \"pricer\"\n",
    "HF_USER = \"Strider221B\" # your HF name here!\n",
    "\n",
    "# Data\n",
    "\n",
    "DATASET_NAME = f\"{HF_USER}/pricer-data\"\n",
    "# Or just use the one I've uploaded\n",
    "# DATASET_NAME = \"ed-donner/pricer-data\"\n",
    "MAX_SEQUENCE_LENGTH = 182\n",
    "\n",
    "# Run name for saving the model in the hub\n",
    "\n",
    "RUN_NAME =  f\"{datetime.now():%Y-%m-%d_%H.%M.%S}\"\n",
    "PROJECT_RUN_NAME = f\"{PROJECT_NAME}-{RUN_NAME}\"\n",
    "HUB_MODEL_NAME = f\"{HF_USER}/{PROJECT_RUN_NAME}\"\n",
    "\n",
    "# Hyperparameters for QLoRA\n",
    "\n",
    "LORA_R = 32\n",
    "LORA_ALPHA = 64\n",
    "TARGET_MODULES = [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
    "LORA_DROPOUT = 0.1\n",
    "QUANT_4_BIT = True\n",
    "\n",
    "# Hyperparameters for Training\n",
    "\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 8\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "LR_SCHEDULER_TYPE = 'cosine'\n",
    "WARMUP_RATIO = 0.03\n",
    "OPTIMIZER = \"paged_adamw_32bit\"\n",
    "\n",
    "# Admin config\n",
    "\n",
    "STEPS = 50\n",
    "SAVE_STEPS = 5000\n",
    "LOG_TO_WANDB = False\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc47d0b-c11a-4106-a13c-c9b0e764f570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T07:56:22.184332Z",
     "iopub.status.busy": "2025-02-02T07:56:22.183504Z",
     "iopub.status.idle": "2025-02-02T07:56:22.216016Z",
     "shell.execute_reply": "2025-02-02T07:56:22.214742Z",
     "shell.execute_reply.started": "2025-02-02T07:56:22.184309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Strider221B/pricer-2025-02-02_13.26.22'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HUB_MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e42a9a2b-6b6d-4f75-a433-512ae91b4d58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T07:56:22.217408Z",
     "iopub.status.busy": "2025-02-02T07:56:22.217088Z",
     "iopub.status.idle": "2025-02-02T07:56:22.169535Z",
     "shell.execute_reply": "2025-02-02T07:56:22.168630Z",
     "shell.execute_reply.started": "2025-02-02T07:56:22.217385Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "hf_token = os.getenv('HF_TOKEN_WR')\n",
    "login(hf_token, add_to_git_credential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84cb1a05-d2fe-484f-b90c-5fb3a637f702",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T07:56:22.170981Z",
     "iopub.status.busy": "2025-02-02T07:56:22.170516Z",
     "iopub.status.idle": "2025-02-02T07:56:22.196320Z",
     "shell.execute_reply": "2025-02-02T07:56:22.194706Z",
     "shell.execute_reply.started": "2025-02-02T07:56:22.170958Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./../data/app_train_dataset_100_rows.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open('./../data/app_test_dataset.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46218f8f-7753-4d58-95db-7723957903d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T07:56:22.199976Z",
     "iopub.status.busy": "2025-02-02T07:56:22.198991Z",
     "iopub.status.idle": "2025-02-02T07:56:22.205471Z",
     "shell.execute_reply": "2025-02-02T07:56:22.204278Z",
     "shell.execute_reply.started": "2025-02-02T07:56:22.199949Z"
    }
   },
   "outputs": [],
   "source": [
    "quant_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                  bnb_4bit_use_double_quant=True,\n",
    "                                  bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                  bnb_4bit_quant_type=\"nf4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b42e927c-97d6-4118-a442-6cb59c97dd6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T07:56:22.206605Z",
     "iopub.status.busy": "2025-02-02T07:56:22.206296Z",
     "iopub.status.idle": "2025-02-02T07:56:26.554852Z",
     "shell.execute_reply": "2025-02-02T07:56:26.553844Z",
     "shell.execute_reply.started": "2025-02-02T07:56:22.206583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint: 1012.0 MB\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "base_model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "print(f\"Memory footprint: {base_model.get_memory_footprint() / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa893642-a5a6-4d75-8f83-7dbb5043e667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T07:56:26.557941Z",
     "iopub.status.busy": "2025-02-02T07:56:26.556499Z",
     "iopub.status.idle": "2025-02-02T07:56:26.565533Z",
     "shell.execute_reply": "2025-02-02T07:56:26.564377Z",
     "shell.execute_reply.started": "2025-02-02T07:56:26.557749Z"
    }
   },
   "outputs": [],
   "source": [
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "response_template = \"Price is $\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3548c0b2-eedf-4ac2-aa31-d845713c0eeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T07:56:26.567210Z",
     "iopub.status.busy": "2025-02-02T07:56:26.566782Z",
     "iopub.status.idle": "2025-02-02T07:56:27.230186Z",
     "shell.execute_reply": "2025-02-02T07:56:27.229193Z",
     "shell.execute_reply.started": "2025-02-02T07:56:26.567175Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6369/1025050698.py:47: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  fine_tuning = SFTTrainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d44891c8cf450aa62018187d318b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lora_parameters = LoraConfig(\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    r=LORA_R,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=TARGET_MODULES,\n",
    ")\n",
    "\n",
    "# Next, specify the general configuration parameters for training\n",
    "\n",
    "train_parameters = SFTConfig(\n",
    "    output_dir=PROJECT_RUN_NAME,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=1,\n",
    "    eval_strategy=\"no\",\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    optim=OPTIMIZER,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    save_total_limit=10,\n",
    "    logging_steps=STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
    "    report_to=\"wandb\" if LOG_TO_WANDB else None,\n",
    "    run_name=RUN_NAME,\n",
    "    max_seq_length=MAX_SEQUENCE_LENGTH,\n",
    "    dataset_text_field=\"text\",\n",
    "    save_strategy=\"steps\",\n",
    "    hub_strategy=\"every_save\",\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=HUB_MODEL_NAME,\n",
    "    hub_private_repo=True,\n",
    "    hub_token=hf_token\n",
    ")\n",
    "\n",
    "# And now, the Supervised Fine Tuning Trainer will carry out the fine-tuning\n",
    "# Given these 2 sets of configuration parameters\n",
    "\n",
    "fine_tuning = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=train, #Somesh - finetuning with 100 e.g. only\n",
    "    peft_config=lora_parameters,\n",
    "    tokenizer=tokenizer,\n",
    "    args=train_parameters,\n",
    "    data_collator=collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f4a77b3-a046-486e-bf47-2180b3e022ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T07:56:27.231393Z",
     "iopub.status.busy": "2025-02-02T07:56:27.231092Z",
     "iopub.status.idle": "2025-02-02T08:07:59.637779Z",
     "shell.execute_reply": "2025-02-02T08:07:59.634964Z",
     "shell.execute_reply.started": "2025-02-02T07:56:27.231365Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstrider221b\u001b[0m (\u001b[33mstrider221b-bh\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/somesh/Git/llm_engineering/playground/wandb/run-20250202_132628-ml8igdbv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/strider221b-bh/huggingface/runs/ml8igdbv' target=\"_blank\">2025-02-02_13.26.22</a></strong> to <a href='https://wandb.ai/strider221b-bh/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/strider221b-bh/huggingface' target=\"_blank\">https://wandb.ai/strider221b-bh/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/strider221b-bh/huggingface/runs/ml8igdbv' target=\"_blank\">https://wandb.ai/strider221b-bh/huggingface/runs/ml8igdbv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 10:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13, training_loss=1.8492786700908954, metrics={'train_runtime': 685.5794, 'train_samples_per_second': 0.146, 'train_steps_per_second': 0.019, 'total_flos': 104612888051712.0, 'train_loss': 1.8492786700908954, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuning.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4833a98-d976-4620-94b5-2f8a444588e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T08:18:59.653140Z",
     "iopub.status.busy": "2025-02-02T08:18:59.652515Z",
     "iopub.status.idle": "2025-02-02T08:19:02.800658Z",
     "shell.execute_reply": "2025-02-02T08:19:02.798983Z",
     "shell.execute_reply.started": "2025-02-02T08:18:59.653109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to the hub: pricer-2025-02-02_13.26.22\n"
     ]
    }
   ],
   "source": [
    "fine_tuning.model.push_to_hub(PROJECT_RUN_NAME, private=True, token=hf_token)\n",
    "print(f\"Saved to the hub: {PROJECT_RUN_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7db60b33-3b03-48bd-af47-6da8190432fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T08:19:13.798786Z",
     "iopub.status.busy": "2025-02-02T08:19:13.797985Z",
     "iopub.status.idle": "2025-02-02T08:19:13.804379Z",
     "shell.execute_reply": "2025-02-02T08:19:13.803354Z",
     "shell.execute_reply.started": "2025-02-02T08:19:13.798745Z"
    }
   },
   "outputs": [],
   "source": [
    "if LOG_TO_WANDB:\n",
    "  wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db648d85-8e35-4d6c-837d-8fd7a5baa04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
